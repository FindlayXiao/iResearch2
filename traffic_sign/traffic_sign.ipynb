{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 爱科研-人工智能科研实训项目\n",
    "## 卷积神经网络（Convolutional Neural Network, CNN）\n",
    "\n",
    "## 项目：计算机视觉 - 交通标志识别\n",
    "\n",
    "在这个notebook文件中，有些模板代码已经提供给你，但你还需要实现更多的功能来完成这个项目。除非有明确要求，你无须修改任何已给出的代码。以**'(练习)'**开始的标题表示接下来的代码部分中有你需要实现的功能。这些部分都配有详细的指导，需要实现的部分也会在注释中以'TODO'标出。请仔细阅读所有的提示。\n",
    "\n",
    "除了实现代码外，你还**需要**回答一些与项目及代码相关的问题。每个需要回答的问题都会以 **'问题 X'** 标记。请仔细阅读每个问题，并且在问题后的 **'回答'** 部分写出完整的答案。我们将根据 你对问题的回答 和 撰写代码实现的功能 来对你提交的项目进行评分。\n",
    "\n",
    ">**提示：**Code 和 Markdown 区域可通过 **Shift + Enter** 快捷键运行。此外，Markdown可以通过双击进入编辑模式。\n",
    "\n",
    "### 让我们开始吧\n",
    "在这个notebook中，你将迈出第一步，来开发可以作为自动驾驶汽车视觉一部分的算法。在现实世界中，你需要拼凑一系列的模型来完成不同的任务；举个例子，你需要先对摄像机获取的图片进行交通标志的探测，再对其标志类别进行识别。在做项目的过程中，你可能会遇到不少失败的预测，因为并不存在完美的算法和模型。你最终提交的不完美的解决方案也一定会给你带来一个有趣的学习经验！\n",
    "\n",
    "![Sample Dog Output](images/preview.png)\n",
    "\n",
    "### 项目内容\n",
    "\n",
    "我们将这个notebook分为不同的步骤，你可以使用下面的链接来浏览此notebook。\n",
    "\n",
    "* [Step 0](#step0): 图像数据预览\n",
    "* [Step 1](#step1): 导入数据集\n",
    "* [Step 2](#step2): 数据增强\n",
    "* [Step 3](#step3): CNN模型构建\n",
    "* [Step 4](#step4): 模型训练\n",
    "* [Step 5](#step5): 测试你的算法\n",
    "\n",
    "在该项目中包含了如下的问题：\n",
    "\n",
    "* [问题 1](#question1): 使用类别不均衡的训练样本进行机器学习模型的训练，可能会产生哪些效果？\n",
    "* [问题 2](#question2): 简要概括早期停止与学习率衰减的原理。\n",
    "* [问题 3](#question3): 思考：采用哪些方法可以进一步提高模型的准确度？\n",
    "\n",
    "---\n",
    "<a id='step0'></a>\n",
    "## 步骤 0: 数据预览\n",
    "\n",
    "### 图像数据\n",
    "\n",
    "图像数据格式为 `ppm`，无法直接预览，我们使用 `PIL` 库中的 `Image` 函数对 `ppm` 格式图像进行处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from pandas import read_csv\n",
    "from PIL import Image as pil_image\n",
    "%matplotlib inline\n",
    "\n",
    "def show_sign(imgs, tags, per_row=2):\n",
    "    n    = len(imgs)\n",
    "    rows = (n + per_row - 1)//per_row\n",
    "    cols = min(per_row, n)\n",
    "    fig, axes = plt.subplots(rows,cols, figsize=(24//per_row*cols,24//per_row*rows))\n",
    "    for ax in axes.flatten(): ax.axis('off')\n",
    "    for i,(img,ax) in enumerate(zip(imgs, axes.flatten())): \n",
    "        ax.imshow(img.convert('RGB'))\n",
    "        ax.set_title(tags[i])\n",
    "\n",
    "### 随机展示100张训练集图片\n",
    "trainlist = glob('./data/train/*/*')\n",
    "example = [rd.randint(0, len(trainlist)-1) for _ in range(100)]\n",
    "imgs = [pil_image.open(trainlist[i]) for i in example]\n",
    "tags = [str(int(trainlist[i][-15:-10])) for i in example]\n",
    "show_sign(imgs, tags, per_row=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标签数据\n",
    "\n",
    "下面我们看看每个数字ID分别对应的交通标志内容。该信息储存在 `./data/signnames.csv` 中， 我们使用 `pandas` 读取并储存该信息于字典 `sign_names` 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_names = dict([(p,w) for _,p,w in read_csv('./data/signnames.csv').to_records()])\n",
    "\n",
    "sign_name_table = PrettyTable()\n",
    "sign_name_table.field_names = ['class value', 'Name of Traffic sign']\n",
    "for i, j in sign_names.items(): sign_name_table.add_row([i, j])\n",
    "\n",
    "print(sign_name_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step1'></a>\n",
    "## 步骤1：导入数据集\n",
    "\n",
    "在下方的代码单元（cell）中，我们以灰度图的形式导入了交通标志图像的数据集：\n",
    "- 我们将图像尺寸统一调整为 32$\\times$32\n",
    "- `train['features']`, `test['features']` - 包含图像文件的numpy数组\n",
    "- `train['label']` - 包含分类标签的数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = (32,32)\n",
    "n_class = len(sign_names)\n",
    "\n",
    "### 导入训练集\n",
    "train = {}\n",
    "train['features'] = []\n",
    "train['label'] = []\n",
    "\n",
    "print('Loading the training set:')\n",
    "for sign in tqdm(range(n_class)):\n",
    "    path = './data/train/' + str(sign).zfill(5) + '/*'\n",
    "    for i in glob(path):\n",
    "        img = pil_image.open(i)\n",
    "        img = img.convert('L')  # 将图像转变为灰度图\n",
    "        train['features'].append(np.array(img.resize(SIZE)))\n",
    "        train['label'].append(sign)\n",
    "train['label'] = np.array(train['label'])\n",
    "\n",
    "### 导入测试集\n",
    "test = {}\n",
    "test['features'] = []\n",
    "test['label'] = []\n",
    "\n",
    "print('Loading the testing set:')\n",
    "path = './data/test/*'\n",
    "for i in tqdm(glob(path)):\n",
    "    img = pil_image.open(i)\n",
    "    img = img.convert('L')\n",
    "    test['features'].append(np.array(img.resize(SIZE)))\n",
    "\n",
    "n_train, n_test = len(train['features']), len(test['features'])\n",
    "\n",
    "### 对数据特征进行维度匹配以便导入神经网络\n",
    "train['features'] = np.expand_dims(train['features'], axis=-1)\n",
    "test['features'] = np.expand_dims(test['features'], axis=-1)\n",
    "\n",
    "print('Total number of classes:{}'.format(n_class))\n",
    "print('Number of training examples =',n_train)\n",
    "print('Number of testing examples =',n_test)\n",
    "print('Image data shape=',train['features'].shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step2'></a>\n",
    "## 步骤2：数据增强\n",
    "\n",
    "### 数据分布\n",
    "\n",
    "通过频率直方图检查各个类别的数据量是否均衡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_imgs_per_class(y, verbose=False):\n",
    "    num_classes = len(np.unique(y))\n",
    "    count_imgs_per_class = np.zeros(num_classes)\n",
    "\n",
    "    for this_class in range(num_classes):\n",
    "        if verbose: \n",
    "            print('class {} | count {}'.format(this_class, np.sum(y==this_class)))\n",
    "        count_imgs_per_class[this_class] = np.sum(y==this_class)\n",
    "    return count_imgs_per_class\n",
    "\n",
    "class_freq = get_count_imgs_per_class(train['label'])\n",
    "print('------- ')\n",
    "print('Highest count: {} (class {})'.format(int(np.max(class_freq)), np.argmax(class_freq)))\n",
    "print('Lowest count: {} (class {})'.format(int(np.min(class_freq)), np.argmin(class_freq)))\n",
    "print('------- ')\n",
    "plt.bar(np.arange(n_class), class_freq , align='center')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim([-1, n_class])\n",
    "plt.title(\"class frequency in Training set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据增强\n",
    "\n",
    "这里的数据增强主要是：\n",
    "- 增加训练集的大小 \n",
    "- 调整了类别分布（由上图可以看出类别分布是不均衡的） \n",
    "\n",
    ">**Note：关于机器学习分类问题中的训练样本不均衡问题，可参考CSDN博客文章：[在分类中如何处理训练集中不平衡问题](https://blog.csdn.net/heyongluoyao8/article/details/49408131)\n",
    "\n",
    "---\n",
    "<a id='question1'></a>  \n",
    "\n",
    "### __问题 1:__ \n",
    "\n",
    "使用类别不均衡的训练样本进行机器学习模型的训练，可能会产生哪些效果？\n",
    "\n",
    "__回答:__ \n",
    "\n",
    "---\n",
    "\n",
    "数据增强后，我们得到每个类别2000张图片 数据增强的方法主要就是从原始数据集中随机选取图片，并应用仿射变换。\n",
    "仿射变换的限制条件为：\n",
    "- 旋转角度我限制在 `[-10，10]` 度之间，如果旋转角度过大，有些交通标志的意思可能就会发生变化\n",
    "- 水平、垂直移动的话，范围限制在 `[-3, 3]` 像素之间\n",
    "- 伸缩变换限制在 `[0.8, 1.2]` 之间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import transform as transf\n",
    "\n",
    "### 仿射变换函数\n",
    "def random_transform(img,angle_range=[-10,10],\n",
    "                    scale_range=[0.8,1.2],\n",
    "                    translation_range=[-3,3]):\n",
    "    '''\n",
    "    The function takes an image and performs a set of random affine transformation.\n",
    "    img:original images\n",
    "    ang_range:angular range of the rotation [-15,+15] deg for example\n",
    "    scale_range: [0.8,1.2]\n",
    "    shear_range:[10,-10]\n",
    "    translation_range:[-2,2]\n",
    "    '''\n",
    "    img_height,img_width,img_depth = img.shape\n",
    "    # Generate random parameter values\n",
    "    angle_value = np.random.uniform(low=angle_range[0],high=angle_range[1],size=None)\n",
    "    scaleX = np.random.uniform(low=scale_range[0],high=scale_range[1],size=None)\n",
    "    scaleY = np.random.uniform(low=scale_range[0],high=scale_range[1],size=None)\n",
    "    translationX = np.random.randint(low=translation_range[0],high=translation_range[1]+1,size=None)\n",
    "    translationY = np.random.randint(low=translation_range[0],high=translation_range[1]+1,size=None)\n",
    "\n",
    "    center_shift = np.array([img_height,img_width])/2. - 0.5\n",
    "    transform_center = transf.SimilarityTransform(translation=-center_shift)\n",
    "    transform_uncenter = transf.SimilarityTransform(translation=center_shift)\n",
    "\n",
    "    transform_aug = transf.AffineTransform(rotation=np.deg2rad(angle_value),\n",
    "                                          scale=(1/scaleY,1/scaleX),\n",
    "                                          translation = (translationY,translationX))\n",
    "    #Image transformation : includes rotation ,shear,translation,zoom\n",
    "    full_tranform = transform_center + transform_aug + transform_uncenter\n",
    "    new_img = transf.warp(img,full_tranform,preserve_range=True)\n",
    "\n",
    "    return new_img.astype('uint8')\n",
    "\n",
    "### 数据增强函数\n",
    "def data_augmentation(X_dataset,y_dataset,augm_nbr,keep_dist=True):\n",
    "    '''\n",
    "    X_dataset:image dataset to augment\n",
    "    y_dataset:label dataset\n",
    "    keep_dist - True:keep class distribution of original dataset,\n",
    "                False:balance dataset\n",
    "    augm_param - is the augmentation parameter\n",
    "                if keep_dist is True,increase the dataset by the factor 'augm_nbr' (2x,5x or 10x...)\n",
    "                if keep_dist is False,make all classes have same number of images:'augm_nbr'(2500,3000 or 4000 imgs)\n",
    "    '''\n",
    "    X_train_dtype = X_dataset\n",
    "    n_classes = len(np.unique(y_dataset))\n",
    "    _,img_height,img_width,img_depth = X_dataset.shape\n",
    "    class_freq = get_count_imgs_per_class(y_train)\n",
    "\n",
    "    if keep_dist:\n",
    "        extra_imgs_per_class = np.array([augm_nbr*x for x in get_count_imgs_per_class(y_dataset)])\n",
    "    else:\n",
    "        assert (augm_nbr>np.argmax(class_freq)),'augm_nbr must be larger than the height class count'\n",
    "        extra_imgs_per_class = augm_nbr - get_count_imgs_per_class(y_dataset)\n",
    "\n",
    "    total_extra_imgs = np.sum(extra_imgs_per_class)\n",
    "\n",
    "    #if extra data is needed->run the dataaumentation op\n",
    "    if total_extra_imgs > 0:\n",
    "        X_extra = np.zeros((int(total_extra_imgs),img_height,img_width,img_depth),dtype=X_dataset.dtype)\n",
    "        y_extra = np.zeros(int(total_extra_imgs))\n",
    "        start_idx = 0\n",
    "        #print('start data augmentation.....')\n",
    "        for this_class in range(n_classes):\n",
    "            #print('\\t Class {}|Number of extra imgs{}'.format(this_class,int(extra_imgs_per_class[this_class])))\n",
    "            n_extra_imgs = extra_imgs_per_class[this_class]\n",
    "            end_idx = start_idx + n_extra_imgs\n",
    "\n",
    "            if n_extra_imgs > 0:\n",
    "                #get ids of all images belonging to this_class\n",
    "                all_imgs_id = np.argwhere(y_dataset==this_class)\n",
    "                new_imgs_x = np.zeros((int(n_extra_imgs),img_height,img_width,img_depth))\n",
    "\n",
    "                for k in range(int(n_extra_imgs)):\n",
    "                    #randomly pick an original image belonging to this class\n",
    "                    rand_id = np.random.choice(all_imgs_id[0],size=None,replace=True)\n",
    "                    rand_img = X_dataset[rand_id]\n",
    "                    #Transform image\n",
    "                    new_img = random_transform(rand_img)\n",
    "                    new_imgs_x[k,:,:,:] = new_img\n",
    "                #update tensors with new images and associated labels\n",
    "                X_extra[int(start_idx):int(end_idx)] = new_imgs_x\n",
    "                y_extra[int(start_idx):int(end_idx)] = np.ones((int(n_extra_imgs),))*this_class\n",
    "                start_idx = end_idx\n",
    "        return [X_extra,y_extra]\n",
    "    else:\n",
    "        return [None,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: import train_test_split from sklearn\n",
    "\n",
    "\n",
    "# TODO: split the data into training and validation subsets\n",
    "X_train,X_val,y_train,y_val= (None, None, None, None)\n",
    "\n",
    "print('*** Before data augmentation:')\n",
    "print('Train set size:{}|Validation set size:{}\\n'.format(X_train.shape[0],X_val.shape[0]))\n",
    "\n",
    "X_extra,y_extra = data_augmentation(X_train,y_train,augm_nbr=2000,keep_dist=False)\n",
    "\n",
    "if X_extra is not None:\n",
    "    X_train = np.concatenate((X_train,X_extra.astype('uint8')),axis=0)\n",
    "    y_train = np.concatenate((y_train,y_extra),axis=0)\n",
    "    del X_extra,y_extra\n",
    "\n",
    "print('*** After data augmentation:')\n",
    "print('Train set size:{}|Validation set size:{}\\n'.format(X_train.shape[0],X_val.shape[0]))\n",
    "\n",
    "with mpl.rc_context(rc={'font.family': 'serif', 'font.size': 11}):\n",
    "    fig = plt.figure(figsize=(9.5,3.5))\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    plt.bar(np.arange(n_class),get_count_imgs_per_class(y_train),align='center')\n",
    "    ax1.set_xlabel('Class')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.set_title('Training Set')\n",
    "    plt.xlim([-1,43])\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    plt.bar(np.arange(n_class),get_count_imgs_per_class(y_val),align='center')\n",
    "    ax2.set_xlabel('Class')\n",
    "    ax2.set_ylabel('Frequency')\n",
    "    ax2.set_title('Validation Set')\n",
    "    plt.xlim([-1,43])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step3'></a>\n",
    "## 步骤 3: CNN模型构建\n",
    "\n",
    "在对图像进行增强之后，我们需要更进一步的方法，来对标志的类别进行识别。在这一步中，你需要实现一个卷积神经网络来对交通标志图像进行分类。你需要从头实现你的卷积神经网络。\n",
    "\n",
    "需要注意的是，在添加卷积层的时候，注意不要加上太多的（可训练的）层。更多的参数意味着更长的训练时间，也就是说你更可能需要一个 GPU 来加速训练过程。万幸的是，Keras 提供了能够轻松预测每次迭代（epoch）花费时间所需的函数。你可以据此推断你算法所需的训练时间。\n",
    "\n",
    "### 数据预处理\n",
    "\n",
    "由于图像像素值分布在 `0-255` 之间，数值较大，因此在将数据导入神经网络之前，我们需要对图像数组进行归一化处理。同时我们需要将标签进行独热编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "def preprocessed(dataset):\n",
    "    n_imgs,img_height,img_width,_ = dataset.shape\n",
    "    processed_dataset = np.zeros((n_imgs,img_height,img_width,1))\n",
    "    for i in range(len(dataset)):\n",
    "        img = dataset[i]\n",
    "        processed_dataset[i,:,:,:] = img/255.-0.5\n",
    "    return processed_dataset\n",
    "\n",
    "X_train, X_val = preprocessed(X_train), preprocessed(X_val)\n",
    "y_train, y_val = to_categorical(y_train, n_class), to_categorical(y_val, n_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【练习】CNN模型架构\n",
    "\n",
    "\n",
    "创建一个卷积神经网络来对交通标志进行分类。在你代码块的最后，执行 `model.summary()` 来输出你模型的总结信息。\n",
    "    \n",
    "我们已经帮你导入了一些所需的 Python 库，如有需要你可以自行导入。如果你在过程中遇到了困难，请查阅[Keras英文文档](https://keras.io/)。\n",
    "\n",
    "在这里可以尝试采用经典的 LeNet-5 架构，如下图所示：\n",
    "\n",
    "![Sample Lenet](images/lenet.png)\n",
    "\n",
    "参考结构如下：\n",
    "\n",
    "01. 5x5 convolution (32x32x1 in, 28x28x6 out)\n",
    "02. ReLU\n",
    "03. 2x2 max pool (28x28x6 in, 14x14x6 out)\n",
    "04. 5x5 convolution (14x14x6 in, 10x10x16 out)\n",
    "05. ReLU\n",
    "06. 2x2 max pool (10x10x16 in, 5x5x16 out)\n",
    "07. 5x5 convolution (5x5x16 in, 1x1x400 out)\n",
    "08. ReLu\n",
    "09. Flatten layers from numbers 8 (1x1x400 -> 400) and 6 (5x5x16 -> 400)\n",
    "10. Concatenate flattened layers to a single size-800 layer\n",
    "11. Dropout layer\n",
    "12. Fully connected layer (800 in, 43 out)\n",
    "\n",
    ">**Note: 这里必须采用函数式写法构建 CNN [参考链接](https://keras.io/models/model/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Input, Dropout, Flatten, Dense, Concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "input_tensor = Input(X_train.shape[1:])\n",
    "x = input_tensor\n",
    "\n",
    "### TODO: 定义你的网络架构\n",
    "                 \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step4'></a>\n",
    "## 步骤4：模型训练\n",
    "\n",
    "模型训练过程中我们使用了早期停止来防止过拟合，并使用学习率衰减寻找局部最优解。\n",
    "\n",
    "---\n",
    "<a id='question2'></a>  \n",
    "\n",
    "### __问题 2:__ \n",
    "\n",
    "简要概括早期停止与学习率衰减的原理。\n",
    "\n",
    "__回答:__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "model.compile(Adam(lr=2e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_name = './best_model.h5'\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=9, verbose=2), # 早期停止\n",
    "             ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.25, min_lr=1e-5, verbose=2), # 学习率衰减\n",
    "             ModelCheckpoint(model_name, save_best_only=True, save_weights_only=True), # 储存最佳模型\n",
    "             TQDMNotebookCallback(leave_inner=True, metric_format='{value:0.3f}')]\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs = 200, batch_size = 256, verbose = 0,\n",
    "                    validation_data=(X_val,y_val), callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制损失函数、精确率与学习速率的变化曲线\n",
    "with mpl.rc_context(rc={'font.family': 'serif', 'font.size': 11}):\n",
    "    fig = plt.figure(figsize=(20,5))\n",
    "    ax1 = fig.add_subplot(131)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_title('Loss')\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.legend(['train', 'val'], loc='upper right')\n",
    "    ax2 = fig.add_subplot(132)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_title('Accuracy')\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.legend(['train', 'val'], loc='lower right')\n",
    "    ax3 = fig.add_subplot(133)\n",
    "    ax3.set_xlabel('Epoch')\n",
    "    ax3.set_title('Learning Rate')\n",
    "    plt.plot(history.history['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step5'></a>\n",
    "## 步骤5 测试你的算法\n",
    "\n",
    "将对测试集的预测结果储存在 `submit.csv` 中，并提交至邮箱 hzhmoon1217@163.com。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 加载最佳模型\n",
    "model.load_weights('./best_model.h5')\n",
    "\n",
    "test_pred = model.predict(preprocessed(test['features']))\n",
    "predictions = np.array([np.argmax(i) for i in test_pred])\n",
    "\n",
    "### 写入CSV文件\n",
    "with open('./submit.csv', 'w') as f:\n",
    "    f.write('Image,ClassId\\n')\n",
    "    for i in range(len(test['features'])):\n",
    "        f.write(str(i).zfill(5) + '.ppm,' + str(predictions[i]) + '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='question3'></a>  \n",
    "\n",
    "### __问题 3:__ \n",
    "\n",
    "思考：采用哪些方法可以进一步提高模型的准确度？\n",
    "\n",
    "__回答:__ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
